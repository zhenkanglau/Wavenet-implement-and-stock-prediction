{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "wavenet_implement.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPGj4o2Q4xss0qG57N9qEVA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zhenkanglau/Wavenet-implement-and-stock-prediction/blob/master/wavenet_implement.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tVje0Ail2ky",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "import torchvision\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torch.utils.data import TensorDataset,Dataset,IterableDataset\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcG-HRiznXPT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2cde8517-affc-4c0e-cc05-2c3921bdecbd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data.zip  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MiITnhU1mWVH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://download.pytorch.org/tutorial/data.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNn89XZ9nfx6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self,input_size,hidden_size):\n",
        "      super(EncoderRNN,self).__init__()\n",
        "      self.input_size=input_size\n",
        "      self.hidden_size=hidden_size\n",
        "      self.embedding=nn.Embedding(input_size,output_size)\n",
        "      self.gru=nn.GRU(hidden_size,hidden_size)\n",
        "    \n",
        "    def forward(self,input,hidden):\n",
        "      embedded=self.embedding(input).view(1,1,-1)\n",
        "      output = embedded\n",
        "      output, hidden = self.gru(output,hidden)\n",
        "      return output,hidden\n",
        "    \n",
        "    def initHidden(self):\n",
        "      return torch.zeros(1,1,self.hidden_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DsiyaYkht8It",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DecoderRNN(nn.Module):\n",
        "  def __init__(self,output_size,hidden_size):\n",
        "    super(DecoderRNN,self).__init__()\n",
        "    self.hidden_size=hidden_size\n",
        "    self.output_size=output_size\n",
        "\n",
        "    self.embedding=nn.Embedding(input_size,output_size)\n",
        "    self.gru=nn.Gru(hidden_size,output_size)\n",
        "    self.out=nn.Linear(hidden_size,output_size)\n",
        "    self.softmax=nn.LogSoftmax(dim=1)\n",
        "  \n",
        "  def forward(self,input,hidden):\n",
        "    output = self.embedding(input).view(1,1,-1)\n",
        "    output = nn.relu(output)\n",
        "    output,hidden = self.gru(output,hidden)\n",
        "    output = self.softmax(self.out(output[0]))\n",
        "    return output,hidden\n",
        "  \n",
        "  def initHidden(self):\n",
        "    return torch.zeros(1,1,self.hidden_size)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwW3Va3A17v2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size=3\n",
        "learning_rate=0.001\n",
        "epoch=1000\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHik7iKy1uqM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a=torch.tensor([1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16],dtype=torch.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHzBxgxz7z4n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "f4e7f442-2842-45bb-e908-2205924040a9"
      },
      "source": [
        "a"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14.,\n",
              "        15., 16.], dtype=torch.float64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRL0M8nWwLY5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "bef73981-2466-49fd-cc2f-12fca54f9f49"
      },
      "source": [
        "[2**l for l in range(1, 10+1)]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2, 4, 8, 16, 32, 64, 128, 256, 512, 1024]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJ375XI_MJeO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CausalConv1d(torch.nn.Conv1d):\n",
        "    def __init__(self,\n",
        "                 in_channels,\n",
        "                 out_channels,\n",
        "                 kernel_size,\n",
        "                 stride=1,\n",
        "                 dilation=1,\n",
        "                 groups=1,\n",
        "                 bias=True):\n",
        "\n",
        "        super(CausalConv1d, self).__init__(\n",
        "            in_channels,\n",
        "            out_channels,\n",
        "            kernel_size=kernel_size,\n",
        "            stride=stride,\n",
        "            padding=0,\n",
        "            dilation=dilation,\n",
        "            groups=groups,\n",
        "            bias=bias)\n",
        "        \n",
        "        self.__padding = (kernel_size - 1) * dilation\n",
        "        \n",
        "    def forward(self, input):\n",
        "        return super(CausalConv1d, self).forward(F.pad(input, (self.__padding, 0)))#(padding_left,padding_right)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQavaWXaI5N8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CausalConv1d(torch.nn.Conv1d):\n",
        "    def __init__(self,\n",
        "                 in_channels,\n",
        "                 out_channels,\n",
        "                 kernel_size,\n",
        "                 stride=1,\n",
        "                 dilation=1,\n",
        "                 groups=1,\n",
        "                 bias=True):\n",
        "        self.__padding = (kernel_size - 1) * dilation\n",
        "\n",
        "        super(CausalConv1d, self).__init__(\n",
        "            in_channels,\n",
        "            out_channels,\n",
        "            kernel_size=kernel_size,\n",
        "            stride=stride,\n",
        "            padding=self.__padding,\n",
        "            dilation=dilation,\n",
        "            groups=groups,\n",
        "            bias=bias)\n",
        "\n",
        "    def forward(self, input):\n",
        "        result = super(CausalConv1d, self).forward(input)\n",
        "        if self.__padding != 0:\n",
        "            return result[:, :, :-self.__padding]\n",
        "        return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZnfo65VQC8m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(ResidualBlock,self).__init__()\n",
        "  \n",
        "  def forward(self,x):\n",
        "    g=torch.sigmoid(x)\n",
        "    h=torch.tanh(x)\n",
        "    f=g*h\n",
        "    res=f+x\n",
        "\n",
        "    return res,f"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-AdkHEBTsfk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83
        },
        "outputId": "14513280-296e-4c6c-eb96-72a038db1b71"
      },
      "source": [
        " res=ResidualBlock()\n",
        " b,c=res(a)\n",
        " print(b)\n",
        " print(c)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([ 1.5568,  2.8491,  3.9479,  4.9814,  5.9932,  6.9975,  7.9991,  8.9997,\n",
            "         9.9999, 11.0000, 12.0000, 13.0000, 14.0000, 15.0000, 16.0000, 17.0000])\n",
            "tensor([0.5568, 0.8491, 0.9479, 0.9814, 0.9932, 0.9975, 0.9991, 0.9997, 0.9999,\n",
            "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7EdmMg78pdVg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class WaveNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(WaveNet, self).__init__()\n",
        "        #self.dconv1=CausalConv1d(1,1,3,1,1,bias=False)\n",
        "        self.dconv1 = nn.Conv1d(1, 1, kernel_size=3, padding=int((1*(3-1))/2), dilation=1,bias=False)\n",
        "        #self.dconv2=CausalConv1d(1,1,3,1,dilation=2,bias=False)\n",
        "        self.dconv2 = nn.Conv1d(1, 1, kernel_size=3, padding=int((2*(3-1))/2), dilation=2,bias=False)\n",
        "        self.dconv3=CausalConv1d(1,1,3,1,dilation=4,bias=False)\n",
        "        self.res1=ResidualBlock()\n",
        "        self.res2=ResidualBlock()\n",
        "    def forward(self,x):\n",
        "      y = self.dconv1(x)\n",
        "      #y,skip = self.res1(y)\n",
        "      #y = self.dconv2(y)\n",
        "     # y,skip = self.res2(y)\n",
        "      #totalskip=totalskip+skip\n",
        "      #y = self.dconv3(y)\n",
        "      #y,skip = ResidualBlock(y)\n",
        "      #totalskip=totalskip+skip\n",
        "      return y\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NnhfwZ7U-dZT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "756640f2-a6bd-40d9-dd5a-65e14683545b"
      },
      "source": [
        "kernel_size=3\n",
        "dilation_rate=2\n",
        "(dilation_rate*(kernel_size-1))/2\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XDFmQZyChB7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "fe51f177-adbc-4eed-920c-c8804702f086"
      },
      "source": [
        "(4 - 1) // 2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PlE3nhjrNJaa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "784f6084-8f5f-4611-cfe0-1d96d4d4c0f7"
      },
      "source": [
        "F.pad(a,(2,0))#(padding_left,padding_right)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.,  0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,\n",
              "        13., 14., 15., 16.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldxh3mS74o-6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "939dff3c-522d-4b64-f310-c5f0ea11c81c"
      },
      "source": [
        "a.view(1,1,-1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOqVn7Ib7jbK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "ab00a514-d367-49e7-d8fc-b8d25360d9ae"
      },
      "source": [
        "wavenet.dconv1.weight"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[1., 2., 3.]]], grad_fn=<MulBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmnIZBSF4ZKn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "72bf4d6e-8130-4115-cf3a-272ef39eaef8"
      },
      "source": [
        "wavenet=WaveNet()\n",
        "torch.nn.init.ones_(wavenet.dconv1.weight)\n",
        "torch.nn.init.ones_(wavenet.dconv2.weight)\n",
        "torch.nn.init.ones_(wavenet.dconv3.weight)\n",
        "wavenet(a.view(1,1,-1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[10., 14., 18., 22., 26., 30., 34., 38., 42., 46., 50., 54., 58.]]],\n",
              "       grad_fn=<SqueezeBackward1>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 152
        }
      ]
    }
  ]
}